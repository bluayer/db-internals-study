# 8장 분산 시스템 개요

데중어설 367pg, 273pg ~~


> 분산 시스템은 공동 목표를 위해 여러 컴퓨터를 네트워크로 연결하여 협력하는 것을 의미한다. 사용자 입장에서는 하나의 단일 시스템처럼 인식된다.

분산 시스템은 네트워크로 연결된 여러 컴퓨터에서 실행되고 있기 때문에, 항상 부분실패의 가능성이 있다는 것을 생각해야한다. 메시지가 늦게 전달되거나, 실패되거나, 순서가 변경될 수 있다.
이러한 문제들은 분산 알고리즘을 통해 독립된 노드들의 동작과 상호작용에 대해 정의하고 통신할 수 있도록 한다.


- 코디네이션 Cordination
- 협동 Cooperation
- 전파 Dissemination
- 합의 Conensus


## 동시수행

만약 한 변수의 값을 연산하는 코드를 2개의 쓰레드에서 수행한다고 가정했을 때, 쓰레드 간 수행순서가 맞지 않으면 결과 값은 의도한대로 나오지 않을 수 있다. 이러한 *동시성* 문제를 해결하기 위해서는 **일관성 모델** 이 필요하다.

동시에 수행되는 작업의 순서를 정하고, 다른 참가자가 순서를 알 수 있도록 공유한다. 이 때 동시성을 지원하는 시스템은 공유 메모리를 사용하여 데이터를 공유한다.

하지만 분산 시스템은 프로세서 별로 상태가 다를 수 있고, 참가자는 메시지 교환을 통해 통신한다는 차이점이 있다.

### 분산 시스템의 자원 공유

만약 데이터베이스를 공유 메모리처럼 사용한다면 동시 요청에 대한 문제를 해결할 수는 있다. 하지만 모든 프로세스의 동기화를
보장하기는 어렵다.

만약 특정 프로세스가 오랜 시간동안 DB로부터 응답을 받지 못한다면, 그 원인은 정확하게 알기 어렵다. 네트워크 문제인지, 과부하 상태인지 알 방법이 없기 때문에 유형에 따라 장애모델을 정의해야한다. (timeout이나 retry 방법과 같은)

네트워크를 통한 통신은 결함이 생길 가능성이 있다. 스위치가 고장날 수 있고, 메시지가 서버에 도착했지만 응답이 유실되거나 연결이 도중에 끊길수도 있다. 이러한 시나리오에 대비하여 시스템을 구축하고, 내결함성을 갖추어야한다.

## 분산 시스템의 오류

### 프로세싱

- 프로세스는 메시지를 전달받고 로컬에서 작업을 수행해야하기 때문에, 메시지를 받는 시점과 응답을 주는 시점은 즉각적이지 않다.
- 또한 메시지가 전달되는 시점에서 프로세싱이 시작된다는 보장도 없다.
- 그리고 노드 환경에 따라 처리하는 속도가 다를 수도 있으며, 작업속도는 가장 느린 원격 서버 속도와 같아진다.

로컬 큐를 사용하는 이유는 다음과 같다.

- 메시지 수신/처리를 시간적으로 분리하고 독립수행하기 위해
- 서로 다른 단계에 있는 요청은 각각 독립된 서브 시스템이 블록되지 않고 처리하기 위해
- 일시적으로 요청이 많이 들어와 부하가 걸리는 경우를 처리하기 위해


## 클럭과 시간

위에서 봤듯이 분산 시스템에서 통신은 즉각적이지 않다. 그래서 특정 시점이나, 구간을 알아야하는 경우 등 시계에 의존해야하는 작업을 처리하기 위해서는 서버 간 동기화나 정확도를 고려해야한다.

예를 들어 스패너는 구글에서 만든 트루타임 API로, 신뢰구간을 명시한다. 이를 통해 트랜잭션 순서를 엄격하게 결정한다.

- 일 기준 클럭 (time-of day clock) : epoch(1970.01.01) 기준으로 흐른 시간, 흔히 현재 날짜와 시간을 나타낸다. NTP 로 동기화를 하며, 로컬 시계와 동기화를 하기 위해 가끔 과거로 뛰는듯한 현상이 발생한다.

- 단조 클럭 (monotonic clock) : 거꾸로 갈 수 없는 시계로, 동기화를 하지 않고 단조 시계의 값 차이를 확인하여 구간을 측정한다. (*This clock is used to tell the elapsed time between two points in the time.)
  https://metacpan.org/pod/Time::Monotonic#:~:text=A%20monotonic%20clock%20is%20a,or%20Daylight%20Savings%20Time%20updates).

### 상태 일관성

앞선 가정들은 "거의 항상 거짓"에 해당된다. 네트워크는 기대보다 오래 기다려야할 수 있고, 시간은 온전히 믿을 수 없으며 내가 읽고 있는 데이터가 최신이라는 보장을 하지 못한다. 하지만 우리가 기대하고자 하는 바를 가정하고 이를 만족하는 방향으로 복잡하게 생각하지 않으면, 특수 상황들을 무시하고 모델을 단순화할 수 있다.

- 일부는 노드 간의 상태 차이를 어느정도 허용해서 충돌 해결이나 읽기 중 데이터 복구방식을 사용해 차이를 해결한다.
- 결과적 일관성을 보장하는 분산 시스템은 정족수를 쿼리해서 복제 노드 사이의 상태 불일치를 해결하는 로직도 있다.

> 정족수?

### 로컬 실행과 원격 실행

원격 API를 호출하고 나서 복잡한 로직들을 수행하는 것은 위험할 수 있다. 로컬과 다르게 원격 노드의 작업은 방식이 다르기 때문에 여러 부분에 있어 이해가 필요하다. <br>
원격 실행을 하게되면 양방향 네트워크 전송, 직렬화/역직렬화 등 단계가 여럿 추가되기 때문에 레이턴시가 늘어나고 성능저하의 원인이 될 수 있다.

### 장애 처리

만약 노드들 중 하나가 점검, 런타임 버그, 소프트웨어/하드웨어 문제로 장애가 발생하는 경우 프로세스는 중단될 수 있다. 그렇기 때문에 분산 시스템은 장애상황에 대비하고 대처하는 고민이 선행되어야한다.

장애 원인은 항상 명확하게 알 수 있는 것은 아니므로, 일부 분산 알고리즘은 하트비트 프로토콜과 장애 검출기(failure detector) 을 사용하여 어떤 노드가 살아있어서 접근 가능한지를 추측하는데 사용한다.

> Each cluster node sends heartbeat messages at specific intervals to other cluster nodes, and expects to receive heartbeat messages from the nodes at specific intervals. If messages stop being received, PowerHA SystemMirror recognizes that a failure has occurred. (https://www.ibm.com/docs/en/powerha-aix/7.2?topic=heartbeating-over-tcpip-storage-area-networks)

<br>

> 장애 검출기

### 네트워크 파티션과 부분장애

네트워크 파티션(네트워크 결함) 은 2개 이상의 서버가 서로 통신할 수 없는 상황으로, 각자 수행한 작업 결과가 충돌할 수 있다.
시스템의 일부분이 제대로 동작하지 않는 부분 장애 상황도 발생한다.

이러한 문제들을 파악하고 대비하기 위해서는 신속한 장애 감지가 필요하다. 하지만 이는 여러 특수상황이 발생하기 때문에 고려할 점이 많다.

- 데이터는 성공적으로 복제했지만 확인 응답을 못받았으면 retry 할지?
- 확인 응답 보낸 노드의 데이터는 읽기를 허용할지?

> 네트워크 결함

> 부분장애

### 계단식 장애

여러 장애상황 중에서도 계단식 장애는 한 부분에서 시작된 장애가 다른 부분으로 전파되는 현상을 말한다.

1.  특정 서버가 죽으면 계속 재연결을 시도해서 서버가 과부하 걸려서 다른 요청을 처리하기 어려워졌다고 가정해보자.
- 재연결 대신 잠시 대기하는 backoff 전략도 있지만, 모든 클라이언트가 해당 전략을 구사하면 역시 부하 발생한다.
- *Jitter(지터)*를 사용하여 변동적인 임의 시간을 추가하여 클라이언트가 동시에 재시도하는 확률을 줄인다.


2. 하드웨어, 에러 등으로 손상된 데이터가 전파되었다고 가정해보자.

- 유효성을 검증하지 않으면 손상된 데이터가 복제되어 정상 데이터를 잃을 수 있다.
- 체크섬과 같은 유효성 검증을 통해 데이터 무결성을 확인해야한다.


## 분산 시스템 추상화

주로 분산 시스템에서 사용되는 단어를 정리한다.

### 링크

앞서 말했듯이 네트워크는 신뢰성이 낮다. 분실되거나 지연되거나 순서가 바뀔 수 있다. 그렇기 때문에 이를 고려하여 신뢰성을 높이는 프로토콜을 설계해보아야한다.

- 손실될 수 있는 링크 (손실 허용링크)

프로세스는 네트워크 링크를 통해 메시지를 교환하는데, 이 메시지 상태는 (1) 목표하는 프로세스에 아직 전달되지 않음. (2) 전송 중에 손실됨. (3) 성공적으로 전달됨 3가지의 가능성이 있다.  <br>

손실 허용링크는 메시지가 무한으로 중복 전달되지 않고, 전송된 메시지만 전달하며, 무한정 전달하는 메시지는 결과적으로는 수신자에게 전달되는 속성이 있다.(하지만 이 또한 완전히 신뢰할 순 없다.) 이는 UDP와 유사하다.


- 메시지 확인 응답

손실 허용링크는 메시지 간 교환에 대한 보장성이 높지만, 메시지가 잘 전달되었는지를 알 수 없다. 그래서 메시지 수신확인용 응답인 ack를 사용하여 수신했다는 것을 정확하게 알 수 있도록 개선할 수 있다.

- 메시지 재전송

하지만 ack를 전송하기 전에 장애가 발생할 수 있고, 메시지가 누락되면 알기 어렵다. 그래서 메시지를 재전송하는 방법도 있다. 링크는 타임아웃 기간 내 대기상태에 있다가 잠재적으로 작업이 실패했다고 가정하면 작업을 재시도한다. (stubborn link)

- 메시지 순서

메시지를 여러번 보낸다고 했을 때 전송한 순서대로 도착하지 않을 수도 있다. 이럴 때는 시퀀스 번호를 사용하여 순서를 판별하거나, 중복을 제거할 수 있다. <br>
** perfect link: 시퀀스 번호 n의 처리여부를 확인하고, 이미 처리된 메시지는 삭제


- 정확히 한 번에 전달

대부분은 최소한번 전달 방식을 사용 / 정확히 한 번만 전달하는 것이 가능할까? <br>

    - 모든 노드가 공통 정보를 공유해야하고, 레코드의 상태에 모든 노드가 동의를 해야한다. -> 불가능한 조건
    - 모든 메시지를 한 번만 처리하고 중복된 메시지를 무시해서 정확히 한 번 전달되는 것처럼 보일 수 있다.

### 두 장군문제

장군 A와 장군 B가 침략국가의 요새를 가운데에 두고 다같이 공격할 시간을 정해야한다고 가정하자.

"오늘 오후 1시에 침략하자" 라는 메시지를 가진 전령은 두 가지 상황에 처할 수 있다.<br>
(1) 무사히 B 장군에게 메시지를 전달하거나 <br>
(2) 적국의 요새에 잡히거나 <br>
<br>

전령을 보낸 장군 A는 메시지가 장군 B에게 전달되었는지를 알 수 없기 때문에 "이 메시지를 봤으면 회신을 해달라(ack)" 라는 조건을 붙이지만, <br>
이 응답 또한 중간에서 유실될 가능성이 있기 때문에 두 장군은 무한히 기다리게 되는 상태에 빠진다.

https://monday9pm.com/메시지-전달-전략과-두-장군-문제-message-delivery-semantics-and-two-generals-problem-f8f1c7646c0b

### FLP 불가능성 이론

비동기 시스템은 항상 일정 시간 내에 합의에 도달할 수 없다는 이론. 프로세스에 장애가 발생했는지, 응답속도가 느린지 알 수 없기 때문에 타임아웃을 사용할 수 없어 어떤 노드가 죽을 위험에 처해있다면 합의에 이를 수 있는 알고리즘은 없음을 증명햇다. <br>

결국 프로세스가 알고리즘 수행시간을 제한하지 않으면 합의 가능한 알고리즘은 존재할 수 없다. <br>
그러나 대부분의 현실의 시스템은 타임아웃을 쓰거나, 의심되는 노드를 식별할 방법이 있으면 합의는 해결 가능하다.

### 시스템 동기성

앞선 두장군 문제, 불가능성 이론으로 보면 적절한 타이밍을 가정하는 것은 분산시스템에서 중요하다. 일부 제약사항을 완화해서 동기 시스템으로 가정하면, 메시지 전송이 무한대로 오래걸리지 않는다고 가정할 수 있다. <br>

> 키워드: raft 알고리즘, 장애 감지 알고리즘, 부분동기모델

----

## 장애모델

분산 시스템에서 발생할 수 있는 다양한 장애를 정의한 모델로, 해당 모델을 기반으로 알고리즘을 설계한다. 분산 시스템은 여러 프로세스가 협조하여 알고리즘을 수행하기 때문에, 장애가 발생하면 전파되어 시스템 전체에 걸쳐 잘못 수행될 수 있다.

### 충돌

프로세스가 수행을 중단하고 메시지를 보내지 않는 현상을 말한다.

- crash-stop : 죽으면 중단한다. 응답이 멈추면 해당 노드는 정확성과 활동성을 더이상 보장할 수 없다.
- crash-recovery : 중단되면 남은 단계를 언젠가 지속하여 수행한다.


### 누락

프로세스가 알고리즘 일부 단계를 건너뛰거나, 참가자끼리 메시지를 교환할 수 없는 상태 등을 말한다.

- 네트워크 파티션 누락 : 개별 프로세스나 그룹 간의 메시지 누락 발생
- 늦은 응답 : 속도가 느린 프로세스의 응답은 다른 프로세스에서 잊혀질 수 있다.


### 임의의 장애

비잔틴 장애라고 불리는 모델은 알고리즘의 의도와 다르게 수행하면서 다른 노드를 속이거나 거짓된 정보를 줄 수 있는 등 임의의 장애가 발생하는 경우를 말한다.

- 항공업계에서는 컴포넌트 응답을 바로 신뢰하지 않고 교차 검증을 진행한다.
- 암호화폐에서 악의적 사용자가 값을 위조하면 시스템을 갈취하는 장애를 유발할 수 있다.


------------------------

# 9장 장애감지

시스템 장애에 대응하기 위해서는 적시에 장애를 감지해야한다. 장애 감지 시스템은 safety와 liveness, 즉 안전성과 활동성을 보장해야한다.

- 활동성 : 의도된 이벤트는 반드시 발생된다. -> 결국에는 응답을 받는다는 희망이 있다.

- 안전성 : 의도되지 않은 이벤트는 반드시 발생하지 않는다. -> 나쁜 일은 일어나지 않는다. 속성이 위반되었다면 이미 손상된 상태로 상태를 취소할 수 없다.

장애감지 알고리즘은 얼마나 빠르게 감지하는지 효율성, 얼마나 정확하게 판단했는지 정확성을 기준으로 평가할 수 있다. 이 두 속성은 트레이드오프이다.

## 하트비트와 핑

- 핑은 주기적으로 메시지를 보내서 일정 시간 내에 응답이 돌아오는지(alive? -> ack)를 확인해서 장애를 감지한다. (timeout)

- 하트비트는 다른 모든 프로세스에게 메시지를 전송하여 자신이 살아있음을 알린다. <br>
  프로세스는 다른 서비스에 요청한 전송 횟수를 기록해서, 임계값을 넘기면 장애로 감지한다. <br>
  각 프로세스는 주변 프로세스들의 카운터를 저장하고,"하트비트가 이동한 경로"를 담아서 하트비트 메시지를 전송하면 <br>
  해당 메시지를 받은 프로세스는 경로에 포함되어있는 모든 프로세스 카운터를 증가시키고 다른 프로세스에 메시지를 전송한다.
  (시장에 가면~)

https://medium.com/@heonjang.lee96/distributed-system은-failure을-어떻게-탐지할까-heartbeat-1-1b7d6f849b17

### 하트비트 아웃소싱

하트비트 아웃소싱 방식은 인접해있는 프로세스의 관점에서 활동성을 판단한다. 모든 프로세스에 브로드캐스팅해서 메시지를 날리지 않고 주변 프로세스 존재여부만 알아도 장애를 감지할 수 있다.

- p1이 p2에 핑 메시지를 전송했는데, 응답하지 않았다면
- 인접한 임의의 p3,p4를 선택해서 p2에게 응답을 보내게 하고,
- 만약 응답이 왔으면 p3 나 p4는 p1에게 확인 응답을 보낸다.

이는 책임을 나누고 장애감지의 신뢰도를 올리는 방안이기도 하다.

https://en.wikipedia.org/wiki/SWIM_Protocol

## 파이 누적 장애 감지

프로세스의 충돌확률을 계산해서 노드의 상태를 감지한다. 예를 들어 마지막 하트비트 도착시간을 바탕으로 다음 시간을 예측하고, 실제로 들어오는 값과 비교해서 감지 정확도를 계산한다.

만약 정확도의 값이 일정 값에 도달하면 해당 노드는 중단된 것으로 보고 네트워크 상태를 동적으로 반영한다.

- 모니터링 프로세스 : 하트비트 도착시간 등의 샘플링을 통해 활동성을 판단
- 판정 : 비정상 상태 표시여부를 판단
- 액션 : 비정상 상태로 판정나면 콜백작업을 실행

## 가십과 장애 감지

각 노드는 전체 노드목록과 하트비트 카운터, 마지막으로 증가된 타임스탬프 값을 가지고 있는다. <br>
해당 정보를 바탕으로 특정 노드가 일정 기간동안 업데이트되어있지 않으면 장애가 발생했다고 판단한다.
해당 방법으로 상태를 전파하게되면 나와 연결이 되어있지 않은 노드들의 장애도 발견할 수 있기 때문에, 더 안정적으로 정보를 전파할 수 있다.

## 장애 전파를 사용한 문제 해결

FUSE 는 2개 이상의 서버가 서로 통신할 수 없는 네트워크 결함이 발생해도 낮은 비용으로 신뢰도 있게 장애를 전파할 수 있는 방법이다.

FUSE는 활성 프로세스를 여러 그룹으로 나누고, 한 그룹에서 장애가 발생하면 해당 그룹의 참가자들이 감지하고 그룹 장애로 전파된다.

- 모든 노드가 장애 사실을 인지하고 대응할 수 있다.
- 작은 하나의 프로세스의 장애로도 그룹 전체의 장애가 될 수 있다.

https://lob-dev.tistory.com/78
