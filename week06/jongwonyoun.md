- [10장. 리더 선출](#10--)
    - [불리 알고리즘](#-)
    - [다음 서열로 리더 역할 승계](#----)
    - [후보/일반 노드 최적화](#--)
    - [초대 알고리즘](#-)
    - [링 알고리즘](#-)
    - [요약](#)
- [11장. 복제와 일관성](#11--)
    - [고가용성](#)
    - [CAP 이론](#cap-)
    - [CAP 이론의 특성](#cap--)
    - [수확률과 산출률](#-)
    - [공유 메모리](#-)
    - [순서화](#)
    - [일관성 모델](#-)
    - [엄격한 일관성 모델](#--)
    - [선형화 가능성](#-)
        - [선형화 지점](#-)
        - [선형화 비용](#-)
    - [순차 일관성 모델](#--)
    - [인과적 일관성 모델](#--)
        - [벡터 클럭](#-)
    - [세션 모델](#-)
    - [결과적 일관성](#-)
    - [조정 가능한 일관성](#--)
    - [증명 복제 노드](#--)
    - [강력한 결과적 일관성과 CRDTs](#---crdts)

# 10장. 리더 선출

- 동기화는 **비용**이 많이 든다
    - 각 단계마다 모든 참가자와 통신해야 한다면 상당한 **통신 오버헤드**가 발생한다
- 동기화 오버헤드를 줄이고 의사 결정에 필요한 **메시지 왕래 횟수**를 줄이기 위해 일부 알고리즘은 분산 알고리즘의 단계를 수행 및 조정하는 **리더(코디네이터) 프로세스**가 있다.


- 일반적을 분산 시스템의 프로세스는 균일하고 모든 프로세가 리더 역할을 맡을 수 있다
    - 오랫동안 리더를 맡을 수 있지만 영구적이진 않다
    - 대부분 장애가 발생할 때까지 역할을 유지한다
    - 장애가 발생하면 어떤 프로세스라도 리더 선출 과정을 시작할 수 있고 선출된 프로세스는 이전 리더의 작업을 이어서 수행한다


- 리더
    - 브로드캐스트된 메시지의 순서를 유지
    - 전역 상태 수집 및 저장, 수신한 메시지를 각 프로세스에 전달
    - 장애 발생 후 시스템을 초기화 하거나 중요한 상태 변경이 발생한 경우 시스템 재구성 작업을 조정한다


- 리더 선출
    - 첫 리더 선출 혹은 이전 리더 프로세스가 충돌하거나 장애가 발생했을 때 발동
    - 선출 작업은 결정론적이어야 한다
        - 하나의 리더를 선출, 모든 참가자는 선출 결과를 인정
    - 선출 알고리즘
        - 지속성(liveness)
            - 거의 항상 리더가 존재하며 선출 과정은 결국 완료됨을 보장한다
                - 선출 과정이 무기한 지속되지 않는다
        - 안정성
            - 한 번에 하나의 리더만 존재할 수 있고 split brain 현상이 절대로 발생하지 않아야 한다
            - 하지만 많은 리더 선출 알고리즘이 이를 위반한다


- 리더 선출은 분산 잠금과 이론적으로 유사하지만 차이가 있다
    - 분산 잠금
        - 누가 잠금을 가지고 있는지 몰라도 된다
        - 특정 프로세스나 그룹에 우선권을 주면 지속성이 보장되지 않는다
            - 잠금을 얻지 못하는 프로세스가 생긴다
    - 리더 선출
        - 모든 구성원이 리더를 인지해야 한다
        - 시스템 입장에서 리더는 오래 유지되면 좋다


- 안정적인 리더가 있으면
    - 원격 노드의 상태를 동기화하지 않아도 되고 메시지 수를 줄일 수 있다
    - 여러 노드가 아닌 하나의 프로세스가 작업을 수행하도록 조정할 수 있다
        - ??


- 리더 시스템의 가장 큰 문제는 리더가 병목이 될 수 있다는 것이다
    - 데이터를 겹치지 않는 여러 개의 독립적인 파티션을 나누고 각 파티션별로 리더를 선출한다
        - 스패너(Spanner)가 이 방식을 사용한다


- 모든 리더 프로세스는 장애가 발생할 수 있다
    - 장애 발생시 새로운 리더를 선출해야 한다
    - 따라서 리더의 장애를 감지하고, 보고하고, 처리할 수 있어야 한다


- ZAB, 멀티 팍소스(Multi-Paxos), 래프트와 같은 알고리즘은 참가자 간의 합의를 도출하는 데 필요한 메시지 수를 줄이기 위해 **임시 리더**를 선출한다
    - 단, 알고리즘마다 리더 선출, 장애 감지, 리더 사이의 충돌 해결 방법은 다르다

https://www.enjoyalgorithms.com/blog/leader-election-system-design

[Amazon Builders' Library 분산 시스템에서 리더 선택](https://aws.amazon.com/ko/builders-library/leader-election-in-distributed-systems/)

https://lamport.azurewebsites.net/tla/tla.html

## 불리 알고리즘

- 불리(bully) 알고리즘은 프로세스의 순위를 기반으로 리더를 선출한다
    - 각 프로세스에 공유 순위를 부여하고, 가장 높은 순위의 프로세스가 리더ㅏㄱ 된다
    - 군주(monarchial) 선출 알고리즘


- 프로세스가 리더의 부재를 감지하거나, 리더가 응답이 없으면 새로운 리더 선출을 시작한다
    - 자기보다 높은 순위의 프로세스에 선출 메시지를 보낸다
        - 응답이 없으면 자기가 가장 우선순위가 높다고 가정하고, 자기가 리더가 되었다는 사실을 하위 프로세스에게 알린다
        - 응답이 오면 자산이 알고 있는 최상위 프로세스에게 다음 단계 진행을 요청한다


- 네트워크 파티션이 발생했을 때 안정성이 보장되지 않는다
    - 따라서 노드가 여러 개의 그룹으로 분할되면 그룹마다 리더가 선출될 수도 있다
    - 이를 split brain 현상이라고 한다


- 또 다른 문제는 상위 노드에 높은 우선권을 부여한다는 점이다
    - 상위 노드가 불안정하면 선출 작업이 무한 반복될 수 있다
- 혹은 선출된 상위 노드가 불안정하면 재선출과 중단이 반복될 수도 있따
- 이는 공유된 노드의 상태를 기반으로 리더를 선출해 해결할 수 있다

> 그룹 내 모든 프로세스들은 다른 프로세스들을 알고 있어야 하므로 동적인 확장이 어렵다

## 다음 서열로 리더 역할 승계

- 불리 알고리즘을 개선한 다양한 버전이 있다
    - 그다음 서열을 갖는 여러 대안 프로세스를 두고 장애 조치를 하면 재선출 작업을 단축할 수 있다


- 모든 리더는 승계할 노드 목록을 제공한다
    - 리더가 죽으면 그 목록 중에서 가장 순위가 높은 프로세스에게 메시지를 보낸다
    - 대안 프로세스 중 하나라도 응답하면 선출 과정을 생략하고 바로 리더가 된다
    - 장애를 감지한 프로세스가 대안 목록 중 가장 우선순위가 높으면 바로 리더가 되고 이를 알린다


- 즉, 대안 프로세스가 살아있다면 선출 과정 단계가 줄어든다

## 후보/일반 노드 최적화

- 선출 과정에서 교환되는 메시지 수를 줄이기 위해 노드를 후보(candidate) 그룹과 일반(ordinary) 그룹으로 나누고, 특정 후보 노드를 리더로 선출하는 방법도 있따


- 일반 프로세스는 후보 노드에 메시지를 전송해 선출 작업을 시작한다
- 응답한 가장 높은 순위의 후보 프로세스를 새로운 리더로 선출하고 이를 알린다


- 동시에 여러 선출 작업이 시작되는 문제를 해결하기 위해 노드별로 딜레이 시간을 적용한다
    - 이 값은 노드 간에 차이가 크므로 효과가 있다
    - 딜레이 시간 사이의 차이는 메시지 라운드트립 시간보다 크다
    - 우선순위가 높은 노드일수록 딜레이 값이 작다

## 초대 알고리즘

- 초대(invitation) 알고리즘은 서로 경쟁하는 대신 서로 자신의 그룹으로 초대한다
    - 그룹별로 리더를 선출하기에, 이론적으로 동시에 여러 리더가 존재할 수 있다


- 각 프로세스는 자신이 유일한 구성원의 리더로 시작하며, 그룹 리더는 자신의 그룹이 아닌 다른 프로세스를 초대한다
    - 리더가 리더를 초대하면 병합한다
    - 리더가 아니라면 리더 ID를 응답한다


- 그룹을 병합할 때 누가 리더가 되는지는 중요하지 않지만 병합하는데 필요한 메시지 수를 최소화하기 위해서는 더 큰 그룹의 리더가 새로운 그룹의 리더가 되어야 한다


- 프로세스를 그룹으로 나누고 새로운 리더 선출 작업을 시작하지 않고 그룹을 병합할 수 있다
- 따라서 선출 작업에 필요한 메시지 수가 감소한다
- ???

## 링 알고리즘

- 링(ring) 알고리즘은 모든 노드는 링 형태로 연결되어 있다
- 각 노드는 링 토폴로지에 대한 정보를 가지고 있다


- 리더 프로세스의 장애를 감지한 프로세스는 새로운 선출 작업을 시작하는 메시지를 링 전역으로 전달한다
    - 각 프로세스는 메시지를 다음 프로세스에 전달하며, 응답하지 않으면 그 다음 노드에게 전달한다


- 각 노드의 형제 노드를 방문하면서 링을 순회하면 정상 노드에 대한 정보를 얻을 수 있다
    - 노드는 자신을 정상 노드 목록에 추가하고 다음 노드로 이동한다
    - 이는 이전에 다룬 장애 감지 알고리즘과 비슷하다


- 선출 작업 메시지가 링 전체를 돌고 나면 활성 노드 목록에서 가장 순위가 높은 노드가 리더로 선출된다


- 메모리 사용량을 줄이기 위해 활성 노드 목록을 저장하는 것이 아니라 순위가 가장 높은 노드 하나만 찾는 방법도 있다


- 링이 여러 그룹으로 분할될 수 있고, 그룹마다 리더가 선출되므로 안정성을 보장하지 않는다

## 요약

- split brain 현상을 해결하기 위해서는 클러스터 구성원 과반수의 동의가 필요하다


- 리더 선출과 합의의 개념은 크게 다르지 않다
- 리더를 선출하기 위해서는 모든 프로세스가 합의해야 한다
- 리더 선출 결과에 합의할 수 있다면 다른 어떤 것에 대해서도 같은 방식으로 합의할 수 있다


- 리더가 존재하는 대부분의 알고리즘은 여러 리더가 존재하는 것을 허용하고 리더 사이의 충돌을 최대한 빠르게 해결한다


- 안정성을 포기하고 여러 리더를 허용하면 성능을 높일 수 있다
    - 대신, 충돌 감지 및 해결을 통해 보장한다

# 11장. 복제와 일관성

- 여러 개의 데이터 복제본을 유지하는 시스템에서 일관성 모델은 시스템의 상태와 작동 방식을 정의하는 중요한 개념이다


- 내결함성(fault tolerance)는 장애가 발생해도 정상적으로 작동할 수 있는 시스템이다
    - 일차적인 목표는 단일 쟁애점(SPOF, single point of failure)을 제거하고 필수 컴포넌트를 이중화하는 것이다
        - 이중화는 사용자에게 완전히 투명하다


- 시스템에 여러 데이터 복제본을 저장하면 일부 서버에 장애가 발생해도 다른 서버가 장애 조치(failover)을 수행해 시스템이 정상적으로 작동할 수 있다
- 진실 공급원이 하나인 시스템은 복제 서버(replica)를 새로운 마스터로 승격시켜 직접 장애를 처리할 수 있다
- 다른 구조의 시스템은 직접적으로 구조를 변경하지 않고 읽기와 쓰기 요청 시 여러 노드의 응답을 수집해 데이터의 일관성을 유지한다


- 데이터 복제(replication)은 시스템에 여러 개의 데이터 복제본을 유지해 시스템을 이중화하는 기술이다
- 여러 복제본을 원자적으로 업데이트하는 작업은 합의 알고리즘과 비슷해 모든 요청마다 수행하기에는 비용이 클 수 있다
- 따라서 노드 간 어느 정도의 상태 차이는 허용하면서 최대한 일관된 데이터를 제공해줄 수 있는 알고리즘이 필요하다


- 데이터 복제는 멀티 데이터 센터에서도 중요하다
    - 지리적 이중화 -> 데이터 가용성 높이고 데이터 센터 장애 대응
    - 복제본이 사용자와 가까워져 전송 레이턴시 줄일 수 있따


- 데이터를 수정하면 복제본도 업데이트 해야 한다
- 데이터 복제 : 쓰기, 복제본 갱신(replica update), 읽기 작업이 중요하다
    - 클라이언트가 이러한 작업 요청하면 이벤트 발동


- 복제본 갱신은 클라이언트 관점에서 쓰기가 완료된 후에 수행된다
- 하지만 갱신 시기와 상관없이 클라이언트가 요청한 순서대로 작업이 수행되어야 한다

## 고가용성

- 고가용 시스템은 일부 노드의 장애 및 오류를 단계적으로 대응할 수 있어야 한다
- 이중화와 복제를 통해 해결할 수 있다
- 하지만 이중화로 인해 여러 복제본을 동기화해야 하는 문제가 발생하고, 복구 메커니즘을 추가로 구현해야 한다

## CAP 이론

- 가용성
    - 모든 요청에 대해 성공적으로 응답할 수 있는 능력을 나타내는 속성
    - 이론적으론 결과적 응답(eventual response)을 의미하지만 현실에서는 너무 오래 걸리면 안된다
    - 즉, 모든 정상 노드는 결과를 반환한다를 의미
- 일관성
    - 원자적 또는 선형화 할 수 있는(linearizable) 일관성을 의미
    - 선형화 가능한 이력은 원래의 실행 순서가 보존되는 일련의 짧은 작업들로 나타낼 수 있다
    - 선형화 가능성은 시스템 상태에 대한 추론을 단순화하고, 분산 시스템이 단일 시스템에서 실행되는 것처럼 보이게 해준다
    - 즉, 모든 결과는 선형화 할 수 있다는 의미


- 네트워크 파티션이 발생해도 일관성과 가용성을 모두 충족하는 시스템이 필요하다
    - 파티션된 노드 사이의 메시지는 제대로 전달되지 않는다


- CAP 이론은 일관성(Consistency)과 가용성(Availability), 분할 내성(Partition tolerance) 사이의 트레이드-오프를 설명한다


- 비동기 시스템은 가용성을 보장할 수 없다
- 또한 네트워크 파티션이 발생했을 때 가용성과 일관성을 동시에 보장하는 시스템은 구현이 불가능하다
    - 대신 (최선의 가용성, 높은 일관성), (최선의 일관성, 높은 가용성)을 보장하는 시스템은 가능하다
        - 최선이란 다른 문제가 발생하지 않으면 시스템은 의도적으로 제약 사항을 위반하지 않고 네트워크 파티션이 발생했을 때 일부 조건은 완화되거나 충족되지 않을 수 있음을 의미한다


- 따라서 CAP 이론은 아래 선택지를 제공한다
    - CP : 높은 일관성과 분할 허용
        - EX) 과반수 노드가 동의해야 하는 합의 알고리즘
    - AP: 가용성 보장 및 파티션 허용


- PACELEC 정리는 CAP 이론을 확장한 개념
    - 네트워크 파티션 발생 시 가용성과 일관성 중 하나 선택
    - 시스템이 정상적으로 작동하더라도 레이턴시와 일관성 중 하나를 선택해야 한다

https://onduway.tistory.com/106
https://osy0907.tistory.com/95

## CAP 이론의 특성

- 클러스터에서 분할된 노드는 일관되지 않은 요청을 처리할 수 있지만 장애가 발생한 노드는 응답조차 하지 않기도 한다
- 즉, 일관성 문제는 노드에 장애가 발생했을 때만 생기는 것이 아니다


- CAP 이론은 노드 충돌이나 다른 종류의 장애보다 네트워크 파티션만을 다룬다


- CAP 이론에 의하면 모든 노드가 정상 가동하고 있어도 노드 간에 연결 문제가 있으면 일관성 문제가 발생할 수 있다
    - 장애가 발생한 노드 수와 무관하게 모든 정상 노드는 올바로 응답할 것이라 예상하기 때문이다


- CAP 이론은 레이턴시를 제한하지 않는다
- 데이터베이스 가용성은 모든 정상 노드가 모든 요청에 응답할 것이라고 가정하지 않는다


- CAP 이론은 분산 시스템의 속성을 정의하고, 장애 시나리오와 발생할 수 있는 여러 문제를 설명한다
- 일관성을 완전히 포기하는 것과 예측할 수 없는 결과를 제공하는 것 사이에는 명확한 차이가 있다
    - 가용성을 우선시하는 데이터베이스도 충분한 수의 복제 노드가 살아있다면 일관된 결과를 제공할 수 있다


- 즉, CAP 이론은 하나의 법칙일 뿐이고 모든 경우를 설명하진 않는다

## 수확률과 산출률

- CAP 이론은 일관성과 가용성을 가장 엄격한 맥락에서 논의한다
    - 선형화 가능성, 시스템이 모든 요청을 응답하는 능력


- 하지만 두 속성을 완화하는게 더 나은 경우도 있기에 더 약한 성질도 다뤄보면 좋다
    - 둘 중 하나를 선택하기 보단 일부 제약 조건을 완화


- 수확률(harvest)
    - 쿼리의 결과의 완전성
- 산출률(yield)
    - 전체 요청 중 성공적으로 완료된 요청 수

## 공유 메모리

- 클라이언트에게는 데이터를 저장하는 분산 시스템이 공유 스토리지인 것처럼 작동한다
    - 노드 사이의 메시지 교환, 통신을 추상화하면 공유 메모리처럼 보일 수 있다


- 읽기, 쓰기 작업이 접근하는 스토리지의 가장 작은 단위의 영역을 레지스터라고 한다
    - 즉, 분산 시스템의 공유 메모리는 레지스터의 배열


- 모든 연산은 호출(invocation)과 완료(completion) 이벤트로 구성된다
    - 연산이 호출된 후 완료하지 못하면 해당 연산은 실패한 것으로 간주
    - 호출 완료 호출 완료 순서면 두 연산을 순차적(sequential)이라고 표현
        - 반대는 동시적(concurrent)


- 여러 리더, 라이터는 동시에 레지스터에 접근 가능하다
- 레지스터 읽기, 쓰기는 즉각적이지 않고 일정 시간 뒤에 수행된다
- 서로 다른 프로세스가 동시에 수행하는 읽기/쓰기 작업은 순차적이지 않다


- 세이프(safe) 레지스터
    - 쓰기 중인 세이프 레지스터를 동시에 읽으면 저장된 값 범위 내에서 임의의 값을 반환한다
- 일반 레지스터
    - 가장 최신 값 또는 동시 수행 중인 쓰기 작업이 쓴 값을 반환
    - 시스템에는 순서가 존재하고 모든 리더가 동시에 같은 값을 읽을 수 없다
- 원자적 레지스터
    - 선형화 가능성을 보장
    - 쓰기 연산에는 다른 읽기 작업이 이전 값을 반환하고 이후에는 새로운 값을 반환하는 특정 시점이 존재한다
    - 원자성은 시스템의 상태에 대한 추론을 단순화할 수 있는 중요한 속성

## 순서화

- 분산 시스템에서는 정확히 언제 특정 이벤트 발생하고, 클러스터 전체에서 새로운 정보에 접근할 수 있는지 알 수 없기 때문에 순서를 보장할 수 없다
    - 참가자별로 데이터베이스를 바라보는 관점이 다르다
    - 따라서 모든 연산을 확인해 호출과 완료 관점에서 정의하고, 범의를 파악해야 한다


- 각 프로세스는 개별적으로 여러 연산을 **순차적**으로 수행한다
- 이 프로세스들의 순차 이력을 조합하면 클러스터 전역의 이력이 만들어진다


- 일관성 모델은 읽기와 쓰기 작업과, 이들이 동시에 수행될 수 있는 여러 방법의 관점에서 이해하면 간단하다

## 일관성 모델

- 공유 메모리 레지스터에 대한 연산은 겹칠 수 이싸
- 따라서 여러 클라이언트가 동시에, 또는 단기간 내에 다른 복제본을 읽거나 수정했을 때 어떻게 처리할 것인지 명확하게 정의해야 한다
- 이는 정답은 없지만 일관성 모델을 정의하는데 매우 중요한 부분이다


- 일관성 모델은 각각 시맨틱과 보장하는 속성이 다르다
- 이를 충족하기 위해 복제 노드가 어떻게 작동해야 하고, 읽기와 쓰기 작업을 요청한사용자에게 어떤 값을 반환해도 되는지를 정의한다


- 즉, 일관성 모델은 데이터 복제본이 여럿 존재하고, 동시 접근이 가능할 때 클라이너트가 받을 수 있는 예상 결과괎을 설명한다


- 일관성을 상태 관점과 연산 관점에서 바라볼 수 있다
    - 상태 관점
        - 허용되는 상태를 규정하고 같은 데이터 복제본 사이의 허용되는 관계를 정의
    - 연산 관점
        - 데이터스토어를 외부에서 바라보고 연산의 수행 순서를 지정


- 글로벌 클럭 없이는 정확하고 확실한 실행 순서를 지정하기 어렵다
    - 각자가 상태와 시간을 각자의 관점으로 바라보기 때문이다 -> 특수 상대성 이론


- 이론적으론 모든 동작마다 시스템 레벨의 잠금을 획득하면 되지만 이는 너무 비효율적이다
- 따라서 일련의 규칙과 정의, 제약 조건을 기반으로 가능한 이력과 결과의 수를 제한한다


- 따라서 CAP 이론에서 일관성을 다룰 때 동기화 비용 측면에서의 일관성도 함께 고려해야 한다


- 동시 읽기, 쓰기는 서로 의존적인 스기 연산을 순차적으로 수행하고, 새로운 값이 전파되는 시점을 지정하면 가능한 연산의 조합의 수를 줄일 수 있다

## 엄격한 일관성 모델

- 복제가 완전히 투명하다
- 프로세스가 새로 쓴 값은 이후 모든 프로세스에서 즉시 사용할 수 있어야 한다


- 하지만 이 모델은 이론적으로만 존재하며 현실적으론 구현이 불가능하다
- 모든 작업의 수행 속도에는 한계가 있기 때문이다

## 선형화 가능성

- 이는 단일 객체와 단일 연산에 대해 가장 엄격한 일관성 모델이다
- 쓰기 작업의 결과를 호출과 완료 이벤트 사이의 특정 시점(선형화 지점)에 모든 리더에서 접근할 수 있어야 한다


- 일련의 동시 수행 연산은 조건을 충족하는 여러 순차 이력 중 하나로 표현할 수 있다
- 여러 개 존재할 수 있으므로 선형화 가능성에는 불확정성이 존재한다


- 수행 시간이 겹치는 연산의 경우 어떤 순서로든 실행될 수 있다
- 하지만 읽기 작업이 특정 값을 반환하면 이후에 수행되는 모든 읽기 작업은 같은 값 혹은 더 최신 값을 반환해야 한다


- 동시 수행 연산의 수행 순서에는 어느 정도의 유연성은 존재하지만 아무렇게나 재배치할 수는 없다
- 또한 연산 중간에 수행 결과가 효력을 가져야만 한다
    - 그렇지 않으면 선형화 지점(linearization point)를 정의할 수가 없다


- 선형화 가능 모델은 프로세스의 로컬 작업 순서와 병렬로 수행되는 다른 작업과의 상대적 순서까지 모두 고려해서 수행 순서를 정의한다
    - 이때 이 순서는 일관되어야 한다


- 선형화 가능한 쓰기 작업은 상호 배제를 의미하기도 한다
    - 여러 동시 쓰기 작업 중 하나만이 먼저 수행될 수 있다


- 연산이 동시에 수행되고 중복되더라도 연산의 효과는 순차적으로 나타난다
- 어떤 연산도 즉시 수행되지 않지만 모두 원자적인 연산처럼 수행된다

### 선형화 지점

- 선형화의 가장 중요한 특징은 가시성(visibility)다
- 작업이 완료되면 모두가 결과를 볼 수 있어야한다
- 선형화는 스테일 읽기(stale read)를 방지하고 단조 읽기(monotonic read)만을 허용한다


- 쓰기 작업의 선형화 지점 이후에는 모든 프로세스가 새로운 값을 읽을 수 있어야 한다
- 이 방식은 임계 영역을 보호하는 잠금과 원자적 읽기/쓰기 또는 읽기-수정-쓰기 연산을 사용해 구현할 수 있다

### 선형화 비용

- 많은 최신 시스템은 선형화를 구현하지 않는다
    - CPU도 기본적으로 지원하지 않는다
- 동기화 작업은 비용이 ㄴ포고 느리며, CPU 사이의 트래픽이 발생하고 캐시도 무효화해야 하기 때문이다
- 하지만 로우 레벨 명령어로 구현할 수 있다


- 동시성 프로그래밍에서는 CAS 연산으로 선형화를 구현할 수 있지만 분산 시스템에서는 조정과 순서화가 필요하다
    - 이는 합의 모듈로 구현한다
- 합의 모듈은 적용된 연산의 결과가 클러스터 전체에서 일관되고 동일한지 확인한다


- 선형화는 원래 지역적 속성이다
- 선형화 가능한 이력을 병합한 이력도 선형화 할 수 있다
    - 다만, 독립적인 두 개체를 병합하는 경우 추가적인 동기화가 필요하다

## 순차 일관성 모델

- 선형화는 비용이 아주 높으므로 조건을 완화하면서 동시에 높은 일관성을 보장할 수 있는 모델이 필요하다
- 순차 일관성(sequential consistency) 모델은 각 프로세스가 실제로 연산을 수행한 순서를 유지하면서, 모든 연산이 어떤 순차적인 차례로 실행된 것처럼 보이게 한다


- 각 프로세서의 관점에서 다른 참가자의 수행 순서는 자신의 이력과 일치한다
- 하지만 프로세스의 이력은 글로벌 이력과 일치하지 않을 수 있다
    - 공통된 시간의 기준이 없기 때문에 이들 사이의 정확한 수행 순서는 알 수 없다


- 이는 원래 멀티 프로세스 기반 프로그램에서 동시성을 처리하는 방식을 규정하기 위해 고안된 모델이다
- 분산 시스템의 맥락에서 연산은 다양한 순서로 실행될 수 있지만 모든 프로세스 관점에서 수행 순서는 같아야 한다
    - 여러 다른 소스에서 요청되는 연산들은 임의의 순서로 수행될 수 있지만 리더의 관점에서 수행 순서는 일관되어야한다


- 스테일 읽기의 원인 중 하나는 복제 노드 사이의 상태 불일치다
- 동일한 순서로 전파된 쓰기 결과가 각각 다른 시간에 도착해 상태가 일치하지 않을 수 있다


- 선형화 가능성 모델과의 가장 큰 차이점은 클러스터 레벨에서 수행 시간을 제한하지 않는다는 것이다
- 선형화 가능성 모델에서 연산의 효과는 일정 시간 범위 내에 나타나야 한다


- 순차적 일관성 모델은 각 프로세스의 관점에서 순서의 일관성만 유지된다면 연산의 결과는 완료 후에 나타나도 된다
- 요청자가 같은 쓰기 연산은 수행 순서가 겹칠 수 없고 실제로 요청된 순서를 유지해야 한다
- 연산의 효과가 나타나는 순서는 모든 리더 사이에 동일해야 한다


- CPU는 기본적으로 순차적 일관성을 보장하지 않는다
- 메모리 배리어(memory barrier) 또는 펜스(fence)를 사용하면 유사하게 구현할 수 있다

## 인과적 일관성 모델

- 인과적 일관성(causal consistency) 모델에서는 인과관계가 성립하는 연산의 순서는 모든 프로세스에서 동일하게 나타나야 한다
- 그렇지 않은 연산 사이의 순서는 프로세스마다 다르게 보일 수 있다


- 작업의 순서는 논리적 시간을 기반으로재구성할 수 있다
- 즉, 작업 간의 순서는 물리적 클럭을 사용하지 않고 논리적으로 정의하며, 모든 프로세스에서 결과가 동일한 순서로 나타나야 한다


- 인과적 일관성이 보장되는 시스템은 세션(session)의 상태가 일관되지 않을 수 있는 여러 서버에 읽기와 쓰기 요청을 해도 데이터베이스의 일관성을 보장한다
    - 단조 일기, 쓰기(motonic read/write), 쓰기 후 읽기(read-your-writes), 읽기 후 쓰기(writes-follow-reads) 속성을 보장한다


- 인과적 일관성은 논리적 클럭과 모든 메시지마다 논리적으로 선행돼야 하는 작업에 대한 메타데이터를 추가해 구현할 수 있다
- 새로운 요청에는 항상 최신 메타데이터 정보가 담겨있다
- 모든 연산은 이전 연산의 결과가 적용된 뒤에 수행할 수 있으므로 순서가 어긋나는 요청은 임시 저장한다


- 순서 보존 서버 클러스터(COPS, Clusters of Order-Preserving Servers)와 아이거(Eiger)는 인과적 일관성을 구현한 대표적인 프로젝트다

> COPS (Cluster of Order-Preserving Servers) is a geo-replicated key-value storage system that guarantees causal+
> consistency


https://timilearning.com/posts/mit-6.824/lecture-17-cops/
https://github.com/wlloyd/eiger

- 두 프로젝트는 일관성 보장을 위해 라이브러리를 사용해 인과관계를 정의하고 종속성을 확인한다
- COPS는 키 버전을 기반으로 의존 관계를 파악한다
- 아이거는수행 순서를 미리 지정한다


- 두 프로젝트 모두 결과적 일관성 모델과는 다르게 맞지 않는 순서로 작업을 요청하지 않는다
    - COPS는 키의 순서로 애플리케이션의 방식으로 순서를 유지하지만 아이거는 마지막으로 쓴 값을 채택하는 방식(last-write-wins)으로 충돌을 해결한다

### 벡터 클럭

- 인과 순서를 정의하면 순서가 맞지 않게 전달된 메시지도 수행 순서를 재구성 할 수 있다
- 또한 메시지 사이의 갭을 채우고, 일부 메시지 누락된 상황에서 결과가 전파되는 상황을 막을 수 있다


- 다이나모와 리악 등의 데이터베이스는 벡터 클럭(vector clock)을 사용해 인과 순서를 유지한다

https://darkstart.tistory.com/144
https://medium.com/@adityashete009/vector-clocks-amazon-dynamodb-part-2-9c39429cf7ff

- 벡터 클럭은 이벤트 간의 부분 순서(partial order)를 정의하고, 여러 부분 순서 사이의 불일치를 해결하는 데 사용된다
- 벡터 클럭을 사용해 공유 시간(common time)과 전역 상태를 구현할 수 있고, 비동기 이벤트를 동기 이벤트로 나타낼 수 있다


- 데이터를 쓰기 전에 해당 키에 대한 값이 프로세스에 존재하면 벡터에서 해당 클럭을 증가시키고, 두 쓰기 작업 사이의 인과관계를 설정한다
- 존재하지 않는다면 새로운 이벤트 체인을 시작하고 신규 버전의 값을 초기화한다

> 인과적 일관성을 구현하기 위해서는 인과 순서를 저장하고 가비지 컬렉션 단계를 추가해야 한다
> 또한 충돌 발생 시 사용자에게 해결을 요청해야 한다
> 벡터 클럭은 충돌 발생 여부를 알려줄뿐 해결 방식은 애플리케이션에 따라서 달라진다

- 인과적 일관성 모델에서는 같은 메모리 위치를 참조하는 쓰기 작업 사이에만 순서를 지정하므로, 독립적인 값에 대한 쓰기 작업 사이에는 충돌이 발생할 수 없다


- 가용성과 성능을 모두 충족하는 일관성 모델은 스테일 읽기뿐만 아니라 충돌이 발생할 수 있는 쓰기 작업도 허용하기 때문에, 모든 복제본이 완전히 일치하지 않을 수 있다

## 세션 모델

- 세션 모델(session model)은 클라이언트의 관점에서 분산 시스템의 상태를 설명한다
- 읽기 및 쓰기를 요청하는 클라이언트가 볼 수 있어야 하는 시스템의 상태를 규정한다


- 지금까지의 일관성 모델은 다중 클라이언트 환경에서의 연산 수행 순서에 초점을 맞춘다
- 하지만 클라이언트 중심 일관성 모델은 하나의 클라이언트가 시스템과 어떻게 상호작용하는지에 초점을 둔다
- 여전히 각 클라이언트의 모든 연산은 순차적이라고 가정한다


- 클라이언트는 여러 복제 노드 중 하나에 연결되는데, 아직 최신 변경 사항이 이 노드로 전파되지 않았더라도 클라이언트는 해당 값의 존재를 모를 수 있다


- 클라이언트는 자신이 쓴 값을 읽을 수 있어야 한다
- 자신이 쓴 값 읽기(Read-own-writes) 일관성 모델에서 쓰기 다음에 수행되는 같거나 다른 복제본에 대한 모든 읽기는 업데이트된 값을 읽어야 한다


- 단조 읽기 모델은 읽을 수 있는 값을 제한한다
- `read(x)`가 `V`를 반환하면 그 이후의 모든 읽기는 `V` 또는 최신값을 읽어야 한다


- 단조 쓰기 모델은 같은 클라이언트가 쓴 값은 쓴 순서대로 나타난다고 가정한다


- 읽기 후 쓰기 모델(write-follows-reads) 모델은 새로운 쓰기 작업을 이전 읽기가 반환한 값의 쓰기 작업 이후에 배치한다


- 단조 읽기, 쓰기, 읽기 후 쓰기 모델을 합친 모델이 파이프라인 기반 RAM 일관성(Pipelined RAM(PRAM) consistency) 또는 FIFO 일관성이다
- 이는 특정 프로세스에서 수행된 쓰기 작업이 해당 수행 순서대로 다른 프로세스에 전파되는 것을 보장한다
- 다른 프로세스의 쓰기 작업의 순서가 실제 순서와 일치하지 않을 수 있는 순차 일관성과는 다르다


- 많은 분산 시스템 개발자가 시스템을 검증 및 단순화하기 위해 클라이언트 중심 일관성 모델을 선택한다

## 결과적 일관성

- 일부 모델은 노드 사이의 어느 정도 불일치를 허용한다


- 결과적 일관성(eventual consistency) 모델에서 변경 사항은 시스템에서 비동기적으로 전파되고, 데이터가 더 이상 변경되지 않는다면 결과적으로 모든 읽기는 가장 최신 값을 반환한다
- 충돌이 발생하는 경우 마지막 스기 채택(last-write-wins) 또는 벡터 클럭 사용 등의 다양한 방식으로 충돌을 해결하므로 최신 값의 개념은 시스템마다 다르다

## 조정 가능한 일관성

- 결과적 일관성 모델 기반 시스템은 다음 세 개의 변수를 사용해 데이터 복제, 읽기 및 쓰기를 조정한다
    - 복제 팩터 N
        - 데이터 복제본을 저장하는 노드 수
    - 쓰기 일관성 W
        - 쓰기가 성공하기 위해 응답해야 하는 노드 수
    - 읽기 이관성 R
        - 읽기가 성공하기 위해 값을 반환해야 하는 노드 수


- (R + W > N)을 만족하는 일관성 수준은 최신 값을 반환한다


- N = 3, W = 2, R = 2인 경우 이상적으로 시스템은 새로운 값을 비동기적으로 세 번째 노드에 복제해야 한다
- 세 번째 노드가 중단된 경우 안티-엔트로피 매커니즘(anti-entropy mechanism)에 의해 값은 결과적으로 전파된다


- 일부 쓰기 요청이 많은 시스템은 W = 1, R = N으로 설정한다
- W = N, R = 1 조합도 항상 최신 값을 읽을 수 있다


- 읽기 또는 쓰기 일관성 수준을 높이면 레이턴시가 증가하고, 노드의 가용성 조건을 충족하기 어려워진다
- 수준을 낮추면 시스템의 가용성은 증가하지만 일관성이 떨어진다


- (N/2) + 1 개의 노드로 구성된 일관성 수준을 쿼럼(quorum, 정족수, 과반수 노드)라고 부른다
- 2f + 1 개의 노드로 구성된 시스템은 최대 f개까지 노드 장애를 허용한다


- 쿼럼 기반 읽기와 쓰기는불완전한 스기 발생 시 단조 읽기를 보장하지 않는다
- 가용성을 포기하고 단조 읽기를 보장하기 이해서는 블로킹 읽기 복구(read-repair) 방식을 사용해야 한다

> 카산드라 : read 쿼리 수행 시 consistency level의 수만큼 replica node를 읽는 과정에서 out-of-date data를 감지한다. 감지 즉시 data를 update하거나, 쿼리값
> return 후 백그라운드로 처리한다.

## 증명 복제 노드

- 쿼럼 기반 읽기는 시스템의 가용성을 높일 수 있다
- 하지만 복제와 과반수 조건으로 인해 저장 비용이 증가한다
- 복제 노드마다 복제본을 저장해야 한다


- 저장 비용은 감시 복제 노드(witness replica) 개념을 사용해 줄일 수 있다
- 각 복제 노드마다 복제본을 저장하는 대신 카피 그룹과 감시(witness) 그룹을 나눈다
- 카피 그룹에는 원래 레코드를 저장하고 감시 그룹에는 쓰기가 발생했다는 사실을 의미하는 레코드를 저장한다
- 하지만 복제본의 수가 너무 적은 경우에는 문제가 될 수 있다 -> ???


- 카피 노드에 장애 또는 쓰기 타임아웃이 발생하면 감시 노드를 카피 노드로 업그레이드하고 레코드를 임시 저장한다
- 노드가 복구되면 업그레이드된 감시 노드를 되돌리거나 복구된 노드를 감시 노드로 활용한다


- n개의 카피 노드와 m개의 감시 노드 구성이 n + m 개의 카피 노드와 동일한 수준의 시스템 가용성을 보장한다
    - 과반의 노드가 읽기와 쓰기 작업을 수행한다
    - 쿼럼 구성원 중 최소 한 개는 카피 노드다


- 그 이유는 레코드가 항상 카피 노드와 감시 노드 중 하나에 존재하기 때문이다
- 장애 발생시 복구 메커니즘은 카피 노드를 최신 상태로 업데이트하고 감시 노드에 데이터를 임시 저장한다


- 이러한 방식을 사용하면 일관성을 유지하면서 저장 비용을 절감할 수 있다
- 스패너와 카산드라가 이러한 방식을 사용한다

## 강력한 결과적 일관성과 CRDTs

- 어느 정도의 비일관성을 허용하고 일치하지 않는 상태는 수행 후에 조정할 수 있도록 연산마다 상태를 추가 저장할 수도 있다
- 대표적인 방식은 레디스에 구현된 CRDTs(Conflict-Free Replicated Data Types)이다


- CRDTs는 충돌이 발생하지 않는 특수한 자료 구조다
- 어떤 순서로 연산을 수행해도 결과는 동일하다
- 이는 분산 시스템에서 매우 유용하다


- CRDTs는 복제 노드 사이의 일시적 불일치를 허용하기 때문에 결과적 일관성 기반 시스템에서 유용하다
- 각 복제 노드는 사전 동기화 없이 독립적으로 연산을 수행한다. 값은 결과적으로 모든 노드에 전파되지만 전달 순서는 실제 순서와 다를 수 있다


- CRDTs의 가장 간단한 예는 연산 기반의 교환 가능한 복제 데이터 타입(CmRDTs, Commutative Replicated Data Types)다.


- 순서가 없는 추가 전용 집합(G-Set, Grow-only Set)도 CRDTs를 사용해 구현할 수 있다


- 충돌이 발생하지 않는 복제된 JSON 타입도 복잡한 형태의 CRDTs다


- CRDTs는 다양한 방법으로 사용될 수 있으며 많은 데이터베이스가 강력한 결과적 일관성(SEC, Strong Eventual Consistency)을 ㅂ장하기 위해 사용한다

https://channel.io/ko/blog/crdt_vs_ot
https://redis.com/blog/diving-into-crdts/
https://yorkie.dev/


