# Chapter 10

동기화 오버헤드를 줄이고 의사 결정에 필요한 메시지 왕래 횟수를 줄이기 위해 일부 알고리즘에는 단계를 수행 및 조정하는 리더 프로세스가 있다.

리더는 전역 상태를 수집 및 저장하고 수신한 메시지를 각 프로세스에 전달하며, 장애 발생 후 시스템 초기화 중 또는 중요한 상태 변경이 발생한 경우 시스템 재구성 작업을 조정한다.

시스템에 안정적인 리더가 있으면 원격 노드의 상태를 동기화하지 않아도 되고 주고받는 메시지 수를 줄일 수 있으며, 하나의 프로세스가 작업을 수행하도록 조정할 수 있다.

## Bully(Monarchial) Algorithm

Election

1. 프로세스는 자신보다 높은 순위의 프로세스에 선출 메시지를 보낸다.
2. 상위 순위 프로세스가 응답할 때까지 대기하고 응답이 없으면 다음 단계를 진행한다. 응답하는 경우 자신이 알고 있는 최상위 프로세스에 다음 단계 진행을 요청한다.
3. 프로세스는 자신보다 더 높은 순위의 프로세스가 없다고 가정하고 하위 프로세스에 새로운 리더가 선출된 사실을 알린다.

문제
1. 네트워크 파티션이 발생하면 최대 한 명의 리더만 존재할 수 있다는 "안정성"이 보장되지 않는다.
2. 상위 순위 노드가 불안정하면 선출 작업이 무한 반복될 수 있다.

### 다음 서열로 리더 역할 승계
Bully 알고리즘의 최적화로, 리더 역할을 승계할 노드 목록을 리더가 제공하고 이를 통해 재선출 작업을 단축시킨다.

### 후보/일반 노드 최적화
선출과정 메시지 수를 줄위기 위해 노드를 candidate group, ordinary group으로 나누고 특정 후보 노드를 리더로 선출한다.

일반 프로세스가 후보 노드에 메시지를 전송해 선출 작업을 시작하며, 응답한 가장 높은 순위의 후보 프로세스를 새로운 리더로 선출한다.

여러 선출 작업이 시작되는 문제를 해결하기 위해 노드별로 딜레이 시간을 두며, 이 값은 노드 간 차이가 클 뿐 아니라 RTT보다 크다.

## Invitation Alogrithm

각 프로세스는 자신이 유일한 구성원인 그룹의 리더로 시작하며, 그룹에 속하지 않은 다른 프로세스를 자신의 그룹으로 초대하여 서로 리더라면 병합한다.

그룹 병합시 누가 새 리더가 되는지는 중요하지 않으나, 병합 시 필요한 메시지 수를 최소화하기 위해 더 큰 그룹의 리더가 새로운 그룹의 리더로 선출돼야 한다. (브로드 캐스팅 메시지 수)

그룹별로 리더를 선출하기 때문에 이론적으로 동시에 여러 리더가 존재할 수 있다.

## Ring Algorithm

모든 노드가 링 형태로 연결되어 있으며 각 노드는 링 토폴로지에 대한 정보가 있다.

리더의 장애 감지를 한 프로세스는 선출 작업을 시작하는 메시지를 링 전역으로 보낸다.

링을 순회하면서 정상 노드에 대한 정보를 수집하며, 활성 노드 목록 중 순위가 가장 높은 노드가 리더로 선출된다.

링 또한 여러 그룹으로 분할 할 수 있고 그룹 별로 리더를 선출할 수 있기 떄문에 안정성을 보장하지 않는다.

## 요약

리더 선출과 합의의 개념은 크게 다르지 않다. 리더 선출 결과에 합의할 수 있다면 다른 어떤 것에 대해서도 같은 방식으로 합의할 수 있음을 의미한다.

---

# Chpater 11. 복제와 일관성

fault tolerance -> SPOF 제거, 이중화

SSOT는 replica를 새로운 마스터로 승격, 그에 반해 다른 시스템은 읽기와 쓰기 요청 시 여러 노드 응답을 수집해 데이터 일관성 유지

## HA

항상 가용성을 높이고 다운 타임을 최소화하려고 애쓴다.

이중화와 복제를 통해 가용성 유지가 가능하지만, 여러 복제본을 동기화해야 하고 복구 메커니즘을 추가 구현해야 한다.

## CAP Theory

가용성은 eventual response를 의미하지만, 현실적으로 응답이 지나치게 오래 걸리는 서비스는 바람직하지 않다.

이상적으로 모든 작업은 일관성을 유지해야 한다. (일관성 : atomic or linearizable consistency를 의미한다.)

네트워크 파티션이 발생해도 일관성과 가용성을 모두 충족하는 시스템을 구축하는 방법이 필요하다.

네트워크는 여러 부분으로 분할될 수 있고 이로 인해 프로세스는 서로 통신이 불가능할 수 있다.

CAP (Consistency, Availability, Partition tolerance)

비동기 시스템에서는 가용성을 보장할 수 없으며, 네트워크 파티션이 ㅂ라생했을 때 가용성과 일관성을 동시에 보장하는 시스템은 구현이 불가능하다.

- CP : 요청을 정상적으로 처리하는 것보다 일관된 데이터를 제공하는 것을 더 중요시한다.
- AP : 일관성을 일부 포기하고 일관되지 않은 데이터를 제공할 수 있다.

### CAP 이론의 특성

CAP 이론은 분산 시스템의 속성을 정의하고 장애 시나리오와 발생할 수 있는 여러 문제를 설명한다.

CAP 이론은 하나의 법칙일 뿐이고 모든 경우를 설명하지 않는다.

### 수확률과 산출률

일관성과 가용성 중에 하나를 선택하기보다는 일부 제약을 조건을 완화할 수도 있다.

이를 위해 똑같은 결과가 보장되는 두가지 조정 가능한 수치인 harvest와 yield를 사용한다.

- harvest : 쿼리의 결과의 완전성을 나타낸다. 실제 쿼리 결과의 로우 수는 100개지만 일부 노드의 장애로 인해 99개만 반환되더라도 쿼리가 실패하고 아무것도 반환되지 않는 것보다 더 나을 수 있다.
- yield : 전체 요청 중 성공적으로 완료된 요청 수를 나타낸다.

트레이드 오프를 따지는 관점이 절대 비교에서 상대 비교로 바뀐다.

## 공유 메모리

분산 시스템의 공유 메모리는 레지스터(읽기와 쓰기 작업이 접근 하는 스토리지의 가장 작은 단위의 영역)의 배열이라고 볼 수 있다.

모든 연산은 invocation과 completion 이벤트로 구성된다.

특정 연산의 호출과 완료 이벤트가 또 다른 연산이 호출되기 전에 발생하면 해당 연산은 다른 연산보다 앞에 있고 두 연산은 sequential이라고 표현한다. 반대는 concurrent이라고 표현한다.

여러 reader와 writer는 동시에 레지스터에 접근할 수 있다.

레지스터 유형)
- Safe register : 쓰기 중인 세이프 레지스터를 동시에 읽으면 레지스터에 저장된 값의 범위 내에서 임의의 값을 반환할 수 있다.
- 일반 register : 레지스터는 항상 가장 최신 값 또는 동시 수행 중인 쓰기 작업이 쓴 값을 반환한다. 따라서 시스템에는 순서가 존재하고 모든 리더가 동시에 같은 값을 읽을 수 없다.
- Atomic Register : 선형화 가능성을 보장한다. 모든 쓰기 연산에는 다른 읽기 작업이 이전 값을 반환하고 이후에는 새로운 값을 반환하는 특정 시점이 존재한다.

## 순서화

읽기는 아무런 영향이 없지만 쓰기는 레지스터의 상태를 변경한다.

데이터의 복제본이 존재하지 않는 경우 수행 순서에는 정답이 없다.

데이터를 이중화하는 시스템인 경우, 더 다양한 상태가 존재할 수 있고 여러 프로세스가 동시에 데이터를 쓴다면 문제는 더 복잡해질 수 있다.

모든 연산을 한 개의 프로세스가 수행한다면 특정 수행 순서를 강제할 수 있으나, 연산이 겹치거나 겹치지 않는 연산의 효과가 즉시 나타나지 않을 수 있다.

수행 순서를 이해하고 결과를 정확하게 추론하기 위해서는 일관성 모델을 정의해야 한다.

## 일관성 모델

여러 일관성 모델은 서로 시맨틱과 보장하는 속성이 다르다.

일관성 모델은 데이터 복제본이 여럿 존재하고 동시 접근이 가능할 때 클라이언트가 반환받을 수 있는 예상 결과값이 무엇인지 설명한다.

일관성을 상태 관점에서 생각하면, 허용되는 상태를 규정하고 같은 데이터 복제본 사이에 허용되는 관계를 정의하는 속성이다.
일관성을 연산 관점에서 생각하면, 데이터 스토어를 외부에서 바라보고 연산의 수행 순서를 지정한다.

일관성과 가용성 뿐만 아니라 동기화 비용 측면에서도 일관성을 고려해야 한다.(CPU 사용, 레이턴시, 복구 관련 정보의 영구 저장을 위한 Disk I/O, Network I/O 등등)

### 엄격한 일관성 모델

프로세스가 새로 쓴 값은 이후 모든 프로세스에서 즉시 사용할 수 있어야 한다.

이론적으로만 존재하며 현실적으로 구현이 불가능하다.

### 선형화 가능성

단일 객체와 단일 연산에 대한 가장 엄격한 일관성 모델

모든 쓰기 작업의 결과를 해당 작업의 호출과 완료 이벤트 사이의 시점에 모든 다른 리더에서 접근할 수 있어야 한다.

동시 수행 연산의 수행 순서에는 유연성이 존재하지만 아무렇게나 재배치하지 않는다.

프로세스의 로컬 작업 순서와 병렬로 수행되는 다른 작업과의 상대적 순서까지 모두 고려해서 수행 순서를 정의하며, 이 순서는 일관돼야 한다. 따라서 여러 동시 쓰기 작업 중 하나만이 먼저 수행될 수 있다.

#### 선형화 지점

선형화의 가장 중요한 특성은 visibility(작업이 완료되면 모두가 결과를 볼 수 있어야 하고, 시스템은 수정사항을 다시 되돌리거나 숨길 수 없다.)

연산은 즉각적이지 않아도 되지만 어느 순간에는 효과가 나타나 즉각적인 연산처럼 보이게 해야 하며, 효과가 나타나는 시점을 선형화 지점이라고 한다.

#### 선형화 비용

선형화를 최신 시스템이 구현하지 않는데, 동기화 작업은 비용이 높고 느리며 노드 사이에 CPU 트래픽이 발생하고 캐시를 무효화해야 하기 때문.

로우 레벨 명령어를 사용해 선형화를 구현하거나, 동시성 프로그래밍에서의 선형화는 CAS를 사용해 구현할 수 있음.

분산 시스템에서 선형화는 조정과 순서화가 필요하며, 이를 합의 모듈을 사용해 구현할 수 있다. 

RIFL : Reusalbe Infra For Linearizability.

**Lease 관련 참고 문서** : https://timilearning.com/posts/mit-6.824/lecture-16-memcache-at-facebook/

### 순차 일관성(Sequential Consistency) 모델

선형화는 비용이 매우 높기 떄문에 조건 완화 + 높은 일관성 보장 모델이 필요.

순차 일관성 모델은 각 프로세스가 실제로 연산을 수행한 순서를 그대로 유지하며, 모든 연산이 어떤 순차적인 차례로 실행된 것처럼 보이도록 한다.

여러 소스에서 임의의 순서로 연산이 실행될 수 있으나, 리더의 관점에서 수행 순서는 일관돼야 한다.

동시에 실행되는 스레드가 새로운 값을 의도된 순서대로 볼 수 있게 하려면 memory barrier(or fence)를 사용해야 한다.

Memory Barrier : 메모리 연산을 순서에 맞게 실행하도록 강제하는 기능

### 인과적 일관성 모델

쓰기 작업 간 인과관계가 존재하고, 이에 따른 논리적 순서에 맞게 전파되어야 하는 경우에 사용하는 모델

인과적 일관성 모델이 보장되는 시스템은 세션이 상태가 일관되지 않을 수 있는 여러 서버에 읽기와 쓰기를 요청하더라도 데이터베이스의 일관성을 보장한다.

구현 프로젝트 예시)

- COPS(Clusters Of Order-Preserving Servers) : 키의 순서, 애플리케이션 방식대로 순서를 유지
- Eiger : LWW

#### 벡터 클럭

Dynamo, Riak은 벡터 클럭을 이용(그렇지 않다면 인과 순서를 유지하여 메시지를 버퍼에 임시 저장하고 인과 순서를 재구성 함)

벡터 클럭은 이벤트 간의 partial order를 정의하고 여러 partial order 사이의 불일치를 해결할 때 사용.

클럭은 초깃값에서 시작하여 새로운 이벤트(쓰기 or 읽기)가 발생할 때마다 증가하며, 타 프로세스로부터 전달받은 클럭 벡터에서 프로세스 별로 알고 있는 가장 높은 값을 자신의 벡터에 갱신한다.

## 세션(Session or Client-Centric) 모델

다른 일관성 모델은 다중 클라이언트 환경에서의 연산 수행 순서에 초점을 맞추지만, 클라이언트 중심 일관성 모델은 하나의 클라이언트가 시스템과 어떻게 상호 작용하는지에 초점을 둔다.

- Read-own-writes consistency model : 쓰기 다음에 수행되는 같거나 다른 복제본에 대한 모든 읽기는 업데이트 값을 읽어야 함
- Monotonic Read model : 특정 값을 read로 반환했다면 동일하거나 이후 값을 반환
- Monotonic Write model : 같은 클라이언트가 쓴 값은 순서대로 나타난다고 가정
- Write-follows-reads model : 새로운 쓰기 작업을 이전 읽기 반환한 값의 쓰기 작업 이후 배치

Monotonic Read/Write + Write-follows-reads => Pipelined RAM(PRAM) Consistency or FIFO Consistency : 특정 프로세스에서 수행된 쓰기 작업이 해당 수행 순서대로 다른 프로세스에 전파되는 것을 보장.

## 결과적 일관성

변경 사항이 시스템에서 비동기적으로 전파되고 데이터가 더 이상 변경되지 않는다면 결과적으로 모든 읽기는 가장 최신 값을 반환한다.

벡터 클럭, LWW 등으로 충돌을 해결한다.

## 조정 가능한 일관성

- 복제 팩터 N : 데이터 복제본을 저장하는 노드 수
- 쓰기 일관성 W : 쓰기가 성공하기 위해 응답해야 하는 노드 수
- 읽기 일관성 R : 읽기가 성공하기 위해 값을 반환해야 하는 노드 수

(R + W > N)을 충족하는 일관성 수준은 읽기와 쓰기 작업 사이에 겹치는 노드가 항상 존재하기 때문에 최신 값을 반환한다.


읽기 또는 쓰기 일관성 수준을 높이면 레이턴시가 증가하고 노드의 가용성 조건을 충족하기 어려워진다. 반대도 존재.

**참고)** Aurora는 4개의 쓰기 세트, 3개의 읽기 세트, 6개의 복사본 쿼럼을 이용한다.

https://aws.amazon.com/ko/blogs/korea/amazon-aurora-under-the-hood-quorum-and-correlated-failure/

## 증명 복제 노드

쿼럼 유지를 위해 복제본 저장 비용이 증가하게 되며, witness replica를 통해 줄이게 됨.

각 복제 노드에 복제하여 저장하는 것이 아니라, 복제 노드를 copy node와  witness 그룹으로 나눔. 감시 그룹에는 쓰기가 발생했다는 사실만을 저장.

copy node에 장애 또는 쓰기 타임아웃이 발생하면 감시 노드를 copy 노드로 업그레이드하고 레코드를 임시 저장.

n개의 카피 노드와 m개의 감시 노드 구성이 n + m개의 카피 노드와 동일한 시스템 가용성 수준을 보장하는 조건

- 과반의 노드가 읽기와 쓰기 작업을 수행
- 쿼럼 구성원 중 최소 한 개는 카피 노드다.

스패너, 아파치 카산드라가 해당 방식을 사용

## 강력한 결과적 일관성과 CRDTs

https://channel.io/ko/blog/crdt_vs_ot


