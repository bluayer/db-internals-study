# Before reading first part
- 데이터베이스를 비교하기 전에 먼저 목표를 명확하게 해야 한다. 작은 편견이라도 결정을 완전히 뒤집을 수 있기 때문이다.
- 데이터베이스를 선택할 때 여로 요소를 고려해야 하며 성능이 가장 중요한 요소가 아닐 수도 있다.
- 변수
    - 스키마와 레코드 크기
    - 클라이언트 수
    - 쿼리 형식과 접근 패턴
    - 읽기와 쓰기 쿼리 비율
    - 위 변수들의 변동폭
- 과정 : 데이터베이스 선택 시 변수 고려 -> 테스트 클러스터 구성 & 워크로드 시뮬레이션 -> 해당 데이터베이스 소스코드 분석
- 데이터베이스 선택은 장기적인 결정이다.
- 스토리지 엔진을 비교할 때 장점과 단점을 모두 살펴봐야 한다.

# Chapter 1. Introduction
## DBMS 구조
1. 트랜스포트 서브시스템은 쿼리를 쿼리 프로세서에 전달
2. 쿼리 프로세서는 쿼리를 해석, 분석 및 검증
3. 분석된 쿼리는 쿼리 옵티마이저에 전달
4. 쿼리에서 논리적으로 불가능한 부분과 중복을 제거한 뒤에 내부 데이터 통계와 데이터 위치 등을 기반으로 가장 효율적인 쿼리 실행 계획 생성 & 선택
5. 선택된 실행 계획은 실행 엔진에서 실행
6. 로컬 쿼리는 스토리지 엔진이 수행

### Storage Engine Component
- Tx manager : 트랜잭션 스케줄링, 데이터베이스 상태의 논리적 일관성 보장
- Lock manager : 트랜잭션에서 접근하는 DB 객체에 대한 잠금 제어. 동시 수행 작업이 물리적 데이터 무결성을 침해하지 않도록 제어
= Access method : 디스크에 저장된 데이터에 대한 접근 및 저장 방식을 정의. 힙파일, B-트리 또는 LSM 트리 같은 자료구조 사용
- Buffer manager : 데이터 페이지를 메모리에 캐시
- Recovery manager : 로그 유지 관리, 장애 발생 시 시스템 복구

## In-memory DBMS vs Disk based DBMS

메모리를 주 저장 매체로 사용하는 이유
- 성능
- 상대적으로 낮은 데이터 접근 비용
- 접근 단위의 세밀함
- 메모리 제어가 디스크 제어보다 프로그래밍적으로 더 간단함

**그러나 휘발성으로 인해 디스크는 메모리보다 유지 관리 측면에서 더 간단하고 비용이 낮다.**

To be next : NVM, Non-Volatile Memory

### Durability at In-memory DBMS
- 모든 작업은 로그 파일에 작업 내용을 "순차적으로(Sequential)" 기록해야 완료된다.
- In-memory DB에서는 복구 시 모든 로그를 재수행하지 않기 위해 백업본을 유지한다.
- 로그 레코드는 배치 단위 백업, 백업본은 스냅샷이기 때문에 이 시점 이전의 로그 삭제(checkpoint)

**In-memory DBMS는 큰 페이지 캐시를 사용하는 디스크 기반 DBMS 같아 보일 수 있으나, 디스크 기반 DBMS는 페이지 전체를 메모리에 캐시해도 직렬화와 데이터 레이아웃을 유지하는 오버헤드가 있어 In-memory DBMS의 성능을 능가할 수 없다.**

Q. 데이터 레이아웃이 트리 구조를 유지한다는 걸 의미할까?

**vs Disk**
- 랜덤 메모리 접근 속도 >> 랜덤 디스크 접근 속도
- 디스크에서는 구현이 불가능하거나 어려운 방식으로 최적화 가능
- 디스크에서는 가변 크기 데이터 제어가 복잡하지만 메모리에서는 포인터를 사용해 쉽게 제어 가능

##  컬럼형 DBMS vs 로우형 DBMS
- MonetDB, C-Store(Vertical의 오픈소스)는 선구적인 칼럼형 오픈소스 데이터 베이스 (첨언 : 실제로 데이터 엔지니어링 쪽에서 온프렘에 Vertica를 운영하고 있는 회사가 좀 있다고 알고 있음)

### 로우형 데이터 레이아웃
- 로우 단위로 저장하면 공간 지역성이 극대화
- 특정 사용자의 모든 정보를 읽을 때는 효율적이지만, 여러 사용자의 특정 필드를 읽을 때는 비효율적이다. (요청하지 않은 필드까지 페이징하기 때문)

### 칼럼형 데이터 레이아웃
- 칼럼별로 다른 파일, 세그먼트에 저장하면 효율적으로 칼럼 단위로 읽을 수 있다.
- 쿼리에 명시되지 않은 칼럼까지 포함해 로우 전체를 읽지 않아도 된다.
- Aggregation에 적합
- Parquet, ORC -> Columnar format
- Apache Kudu, ClickHouse -> DBMS

### 차이점과 최적화 기법
- 같은 칼럼의 여러 값을 한 번에 읽으면 캐시 활용도, 처리 효율성 증가(feat CPU Vector Calc)
- 자료형 별로 저장하면 압축률 증가

둘 중 선택할 때 액세스 패턴을 파악하기.

### 와이드 칼럼 스토어
- BigTable, HBase
- 데이터를 다차원 맵으로 표현하고 여러 칼럼을 칼럼 패밀리(같은 자료형 집합)) 단위로 저장
    - 칼럼 패밀리 데이터는 로우 형식으로 저장
    - 키 단위 액세스 패턴에 적합

``` json
// example : Webtable
{
    "com.cnn.www": {
        contents: {
            t6: html: "<html>..."
            t5: html: "<html>..."
        }
        author: {
            t9: cnnsi.com: "CNN"
        }
    }
}
```

- 각 로우는 로우 키와 매핑하고 관련있는 칼럼끼리 칼럼 패밀리(contents, anchor 필드) 단위로 저장한다.
- 칼럼 패밀리의 칼럼은 이름과 수식자(html, cnnsi.com)으로 구성된 칼럼 키로 식별할 수 있다.
- 칼럼 패밀리는 시간별로 여러 버전의 데이터를 유지한다.

## 데이터 파일과 인덱스 파일

DBMS 주 목적 : 데이터 저장, 빠르게 데이터 검색 -> 그렇다면 How?

다음과 같은 이유로 일반 파일을 사용하지 않음
- 저장 효율성
- 접근 효율성
- 갱신 효율성

**데이터 파일에는 데이터 레코드를, 인덱스 파일에는 레코드에 대한 메타데이터를 저장하고 이를 사용해 데이터 파일에서의 레코드 위치를 찾을 수 있다.**

파일 <- 페이지(레코드 또는 슬롯 페이지의 집합) <- 디스크 블록

삭제 시 즉시 삭제하지 않고 마커로 가리며, 가비지 컬렉션 중에 최신 레코드로 갱신되며 기존 값 삭제

**예시**
- Postgresql에서는 tombstone으로 삭제 마커를 주며, vacuum을 통해 가비지 컬렉션을 진행(참고 : https://bluayer.com/66)
- DynamoDB 같은 Key-value DBMS도 TTL 같은 요소 처리를 할 떄 비슷하게 처리. 가비지 컬렉션 같은 프로세스를 통해 TTL 요소를 처리

### 데이터 파일
- Index-Organized Table : 인덱스에 실제 데이터 레코드 저장. 데이터는 키 순서로 정렬. 팀색 횟수 감소
- Heap-Organized Table : 레코드 삽입순 저장. 검색 시 실제 위치를 가리키는 인덱스 필요
- Hash-Organized Table : 레코드룰 카 해시 값에 해당하는 버킷에 저장. 조회 속도 향상 가능

### 인덱스 파일
- 데이터 파일에 대한 인덱스를 primary 인덱스라고 한다.
- 다른 인덱스는 모두 secondary 인덱스라고 한다.
    - Secondary 인덱스는 데이터 레코드를 직접 가리키거나 해당 레코드의 기본 키를 저장한다.
    - primary 인덱스는 키별로 하나의 레코드만 가리키는 반면, secondary index는 키별로 여러 레코드를 가리킬 수도 있다.
- 레코드 정렬 순서, 검색 키 정렬 순서가 같은 인덱스는 clustered index.
- 데이터가 다른 파일에 저장되어 있고 인덱스 키를 기준으로 정렬되지 않은 인덱스는 non-clustered index

### 기본 인덱스를 통한 간접 참조
- 데이터 레코드 직접 참조 : 디스크 탐색 오버헤드 감소 but 레코드 갱신 혹은 위치 변경할 때마다 포인터를 수정해야 함.
- 기본 키 인덱스를 통한 접근 : 포인터 갱신 비용이 줄지만, 레코드 위치를 찾는 과정이 추가

**읽기 작업이 많다면 인덱스 개수가 여러 개여도 괜찮지만, 쓰기 작업이 많고 인덱스 개수가 많다면 포인터 갱신이 문제가 될 수 있음.**

따라서, 일부 시스템은 오프셋 대신 기본 키를 사용해 데이터를 간접 참조

혼용법 :인덱스에 데이터 파일 오프셋과 기본 키를 모두 저장하고 참조 시 우선 오프셋이 유효한지 확인한 다음, 위치가 변경됐다면 기본 키 인덱스를 통해 데이터를 찾고 새로운 오프셋으로 인덱스를 갱신.

## 버퍼링, 불변성, 순서화
데이터베이스 자료 구조의 공통점
- 버퍼링을 사용한다(또는 사용하지 않는다.)
    - 데이터를 디스크에 쓰기 전에 일부를 메모리에 저장할지 여부를 정의
    - 의도적 버퍼링 : B-트리 노드에 인메모리 버퍼를 추가해 I/O 비용을 낮춘다던지(지연형 B- 트리) 등등
- 불변 파일을 사용한다(또는 가변 파일을 사용한다.)
    - append-only or in-place update
- 저장할 때 값의 순서를 유지한다.(또는 유지하지 않는다.)
    - 데이터 레코드를 키 순서로 저장할지에 대한 여부
    - 순서화는 특정 데이터 레코드 검색 뿐만 아니라 range scan에도 중요
    - 임의 순서 저장 시 쓰기 시간 최적화 가능

# Chapter 2. B- Tree
대부분의 가변 자료 구조는 in-place update 방식을 사용

스토리지 엔진은 보통 여러 버전의 레코드를 데이터베이스에 저장. (MVCC or Slotted page organization)

but 책에서는 쉬운 이해를 위해 "모든 키는 고유한 위치에 저장된 한 개의 데이터 레코드를 가리킨다"고 가정.

## 디스크 기반 스토리지용 트리
BST : Tree fanout이 낮아 트리 밸런싱, 노드 재배치, 포인터 갱신이 잦음. 따라서 트리 유지 비용이 커서 디스크 기반 자료구조로 부적합

BST를 디스크에서 제어시 문제점
- Locality : 노드가 키 순서에 따라 삽입되지 않기 때문에 새로운 노드와 부모 노드가 가까운 위치에 저장되지 않을 수 있음
- Height of tree : 트리의 높이가 높으면 디스크 탐색 비용 증가

**즉 디스크에 저장하려면 다음과 같은 조건 필요**
- 인접한 키의 지역성을 높이기 위한 높은 팬아웃
- 트리 순회 중 디스크 탐색 횟수를 줄이기 위한 낮은 트리 높이

**참고** : 팬아웃과 높이는 반비례.

## 디스크 기반 자료 구조
공간과 시간 복잡도를 모두 만족하는 자료구조라도 디스크에 적합하지 않을 수 있음.

디스크와 같은 영속적 저장 매체의 한계를 고려해야 함.

### HDD

- 전통적 알고리즘 대다수가 HDD 기반.
- 최근에는 바이트 단위로 접근할 수 있는 NVM을 사용하는 새로운 자료 구조가 연구 중
- 디스크에서는 Seek이 랜덤 읽기 비용의 많은 부분을 차지 -> 연속된 메모리 섹터를 읽거나 쓰는 순차 I/O를 극대화해야 함.

### SSD

참고 자료 : https://tech.kakao.com/2016/07/13/coding-for-ssd-part-1/
~~~예전에 읽었었지만 사실 기억이 가물가물~~~

- 메모리 셀 구조. 
- 셀 -> 스트링 -> 페이지(스트링 배열) -> 블록 -> 플레인 -> 다이
- 페이지는 읽고 쓸 수 있는 가장 작은 단위지만 삭제할 수 있는 가장 작은 단위는 블록
- 페이지 ID를 실제 위치와 매핑하고, 비어있거나 쓰여진 혹은 삭제된 페이지를 관리하는 플래시 메모리 컨트롤러 : "FTL"
    - FTL은 안전하게 지워도 되는 블록을 찾는 동안 가비지 컬렉션도 수행
    - 일부 블록에 이미 사용 중인 페이지가 있다면, 해당 페이지를 다른 위치로 옮기고 페이지 ID 매핑도 알맞게 수정
    - 사용하지 않는 블록은 재사용을 위해 삭제
- SSD, HDD 모두 메모리 청크 단위로 데이터를 참조 -> 블록 디바이스에서 하나의 워드를 읽으면 해당 워드를 포함하는 블록 전체를 읽게 됨
- SSD는 랜덤, 순차 I/O의 차이가 중요하지 않지만 prefetch(자주 사용하는 걸 미리 메모리에 올리는 방식으로 보임), 연속 페이지 읽기, 내부 병렬 처리로 인해 차이는 존재

### 디스크 기반 자료구조
**효율적인 디스크 기반 자료 구조 설계가 어려운 이유** : 가장 작은 작업 단위가 블록이라는 제약 때문(블록의 특정 위치를 참조하려면 블록 전체를 읽어야 함)


대부분 디스크 기반 자료 구조 : 포인터를 직접 관리, 계산

따라서 긴 종속 관계 사슬이 생기면 유지 관리가 어렵고 복잡해지기 때문에 전체  포인터 수를 제한하고 저장 범위를 최소화하는 편이 좋음

**디스크 기반 자료 구조는 저장 매체의 구조를 고려해서 설계 & 디스크 접근 횟수를 줄여야 함**

## 유비쿼터스 B-Tree
B-트리는 팬아웃이 높고 높이가 낮은 BST 기반 트리이며 키 순서 보장

### B- Tree 계층
- Root node : 트리 최상위 노드
- 내부 node : 루프와 리프 노드를 연결하는 노드. 트리에는 일반적으로 한 레벨 이상의 내부 노드가 있음
- 리프 노드 : 자식노드가 없는 트리의 최하위 계층 노드

B- 트리는 페이지 기반 자료구조이기 때문에 노드와 페이지가 같은 의미로 쓰이기도 한다.

**팬아웃이 높으면 트리의 균형을 유지하는 데 필요한 트리 구조 변경 비용을 낮출 수 있고 키와 포인터를 같은 블록 또는 연속된 블록에 저장해 불필요한 탐색을 줄일 수 있다.**

### 구분 키
- B- 트리 노드에 저장된 키를 인덱스 엔트리, 구분 키, 또는 디바이더 셀이라고 부른다.
- 각 키는 트리를 해당 키 범위의 서브트리로 분할한다.
- 키는 정렬돼있기 때문에 이진 검색에 사용할 수 있다.
- B- 트리는 상향식. 리프 노드가 많아질수록 내부 노드와 높이가 증가한다.
- B-트리는 나중에 삽입 및 업데이트 될 노드의 공간을 미리 확보해둔다. 높은 점유율은 성능에 부정적인 영향을 미치지 않는다.

### B- 트리 알고리즘
- 탐색 : 특정 키 또는 바로 앞 키 찾기
- 포인트 쿼리, 업데이트, 삭제 작업 : 정확히 일치하는 키
- 범위 스캔, 새로운 노드 삽입 : 대상 키의 바로 앞의 값 찾기

### 키 개수
다양한 전략이 있다.

### B- 트리 노드 분할
리프 노드에 남은 공간이 없는 노드 : overflow -> 분할해야 하며 조건은 다음과 같음

**분할 조건**
- 리프 노드 : 노드에 최대 N개의 key-value 쌍을 저장할 수 있고 새로운 쌍 삽입 시 용량이 초과되는 경우
- 리프가 아닌 노드 : 노드에 최대 N+1개의 포인터를 저장할 수 있고 포인터 추가 시 용량이 초과 되는 경우

노드 분할은 새로운 노드를 할당해 키의 절반을 새로운 노드로 옮기고 첫 번째 키와 포인터(승급 키)를 부모 노드에 추가하는 방식


**분할 과정**
1. 새 노드 할당
2. 분할 노드 키의 절반을 새로운 노드로 복사
3. 새로운 키를 알맞은 노드에 삽입한다.
4. 분할 노드의 부모 노드에 분할 키와 새로운 노드를 가리키는 포인터를 추가

### B-트리 노드 병합
키를 삭제하다보면 노드에 저장된 값이 너무 적은 경우 발생 : underflow -> 병합 or 리밸런싱

**병합 조건**
- 리프 노드 : 노드에 최대 N개의 key-value 쌍을 저장할 수 있고 두 노드의 총 쌍의 수가 N보다 작거나 같은 경우
- 리프가 아닌 노드 : ㄴ드에 최대 N+1개의 포인터를 저장할 수 있고 두 노드의 포인터 수의 합이 N+1보다 작거나 같은 경우

**병합 과정**
1. 모든 키를 오른쪽 노드에서 왼쪽 노드로 복사
2. 부모 노드에서 오른쪽 노드를 가리키는 포인터를 제거 (리프 노드 병합이 아니면 강등)
3. 오른쪽 노드를 제거

